{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defactoring ‘Pace of Change’\n",
    "\n",
    "## Exploring Code Review Methods for Textual Scholarship and Literary Studies\n",
    "\n",
    "## Introduction\n",
    "Coding and code peer review are still far from generally accepted as scholarly technique and method in textual scholarship and literary studies. In this paper we argue that coding can be regarded simply as an extension of scholarly practice necessitated by the increased application of code both as a means to create digital objects as cultural artefacts and as a means of analysis within the humanities. This in turn gives rise to the question if and how such methods can be evaluated and peer reviewed. As a contribution to the exploration of methods for peer reviewing code and digital approaches to analysis we present a Jupyter Notebook that ‘defactors’ the analytic code underlying a recent publication in the field of literary studies. We then reflect on our approach and discuss how this may contribute to future development of peer reviewing methods in (digital) humanities.\n",
    "Abstract\n",
    "\n",
    "We start from the assertion that coding and code—as the source code of computer programs that is readable to humans and which drives the performative nature of software (Ford 2015, Hiller 2015)—can be inherent parts of scholarship or scholarship by and of themselves. That is: we assert that code can be scholarly, that coding can be scholarship, and that there is little difference between the authorship of code or text (Van Zundert 2016). The dichotomy that has been often sought between on the one hand a ‘pure’ intellectual realm associated with scholarly writing and academic print publication, and on the other hand the ‘material labour’ associated with for instance instrument making or programing, is artificial. \n",
    "\n",
    "We argue the validity of this assertion along Burgess and Hamming (2011) and Clement (2016). These scholars refer to earlier work in which Bruno Latour (1993) casts the defining characteristic of modernity as a process of ‘purification’ which aims to contrast the human culture of modernity to nature. Burgess and Hamming observe a congruent process in academia: “Within the academy we see these processes of purification and mediation at work, producing and maintaining the distinction between intellectual labor and material labor, both of which are essential to multimedia production” (Burgess & Hamming 2011:¶11). This process serves to distinguish between scholarly and non-scholarly activities: “The distinction between intellectual and material labor is pervasive throughout scholarly criticism and evaluation of media forms. […] In addition, any discussion of scholarly activities in multimedia format are usually elided in favor of literary texts, which can be safely analyzed using traditional tools of critical analysis.” However, this distinction is based upon a technological fallacy already pointed out—as Burgess and Hamming note—by Richard Grusin in 1984. Grusin argued that Hypertext has not changed the nature of text essentially, as writing has always already been hypertextual through the use of indices, notes, annotations, and intertextual references. To assume that the technology of Hypertext has unvealed or revolutionary activated the associative nature of text, amounts to the fallacy of ascribing the associative agency of cognition to the technology, which however is of course a ‘mere’ expression of that agency.\n",
    "\n",
    "Analogous to Burgess and Hamming, we argue that relegating the evaluation of scholarship to the reviewing of print publications is an equal fallacious ascribing of agency to the technology of written text. Such a narrow understanding of scholarship presupposes that something is scholarship because it is in writing, that writing makes it scholarship. \n",
    "It is possible to evade all such possible technological fallacies by understanding scholarship as argument. We argue therefore that scholarship in essence is argument, and that technologies enable to shape and express that argument. This is not to say that technologies are mere inert and neutral epistemological tools, obviously different technologies shape and affect argument in different ways. Different technologies can therefore enrich scholarly argument. Scholarship is thus not bound to the use of text as an epistemological technology, but essentially is in the shaping of an argument. Text and writing may still be the most celebrated semiotic technologies to express an argument, but computer code understood as ‘just another’ literacy (cf. Knuth 1984, Kittler 1993, Vee 2013) can equally be the carrier of scholarly argument. \n",
    "\n",
    "However, the acceptance of code as another form of scholarly argument presents problems to the current scholarly process of evaluation because of a lack of well developed methods for reviewing and critiquing scholarly code. Digital humanities as a site of production of non conventional research outputs—digital editions, web based publications, new analytical method, and computational tools for instance—has spurred the debate on evaluative practices in the humanities considerably, exactly because practitioners of digital scholarship acknowledge that much of the relevant scholarship is not expressed in the form of traditional scholarly output. Yet the focus of review generally remains on “the fiction of ‘final outputs’ in digital scholarship” (Nowviskie 2011), on old form peer review (Antonijevic 2016), and on approximating equivalencies of digital content and traditional print publication (Presner 2012). Discussions around the evaluation of digital scholarship have thus “tended to focus primarily on establishing digital work as equivalent to print publications to make it count instead of considering how digital scholarship might transform knowledge practices” (Purdy & Walker 2010:178, Anderson & McPherson, 2011). As a reaction digital scholars have stressed how peer review of digital scholarship should foremost consider how digital scholarship is different from conventional scholarship. They argue that review should be focussed on the process of developing, building, and knowledge creation (Nowviskie 2011), on the contrast and overlap between the representationality of conventional scholarship and the strong performative aspects of digital scholarship (Burgess & Hamming 2011), and on the medium specificity of digital scholarship (Rockwell 2011).\n",
    "\n",
    "The debate on peer review in digital scholarship however, has been geared much to high level evaluation, concentrating for instance on the issue how digital scholarship could be reviewed in the context of tenure track evaluations. Very little has been proposed as to concrete techniques and methods for more practical level applied peer review of program code. Existing practical guidance pertains to digital objects such as digital editions (Sahle & Vogler 2014) or to code as cultural artefact (Marino 2006), but no substantial work has been put forward on how to peer review scholarly code. We are left with the rather general statement that “traditional humanities standards need to be part of the mix, [but] the domain is too different for them to be applied without considerable adaptation” (Smithies 2012), and the often echoed contention that digital artefacts should be evaluated as such and not as to how they might have been documented in conventional articles. The latter argument probably most succinctly put by Geoffrey Rockwell (2011): “While such narratives are useful to evaluators […] they should never be a substitute for review of the work in the form it was produced in.”\n",
    "\n",
    "Yet, the problem is growing more urgent. Increasingly, code is created and used as a mechanism of analysis in textual scholarship and literary studies—cf. for instance Enderle 2016, Jockers 2013, Piper 2015, Rybicki et al. 2014, and Underwood 2014. The algorithms, code, and software that underpins the analyses in these examples of scholarship are not standardized ‘off the shelf’ software productions. These code bases are nothing like a software package or product such as AntConc that can be viewed as a generic and packaged distributable tool; a tool that might be subject to a scholarly type of tool criticism explaining and opening it for reuse by other scholars. Instead these codebases are bespoke code: they are one-off highly specific and complex analytical engines, tailored to solving one highly specific research question based on one specific set of data. Reuse, scalability, and ease-of-use are, justifiably (Baldrigde 2015), not specific aims of these code objects at all. Such might be the case with generic software, but these programs have been algorithmic instruments tailor made to serve the research case at hand. As such—and following what was argued above—we must regard these code bases as an inherent part of the scholarly argument they contribute to. And as such they deserve and require specific and rigorous peer review, like any argument in humanities research. How such peer review should be conducted is, however, a large unknown.\n",
    "\n",
    "As a contribution to the challenges of code peer review we present an experimental technique we call defactoring. Drawing on Braithwaite (2013), we have re-configured the program code that underpins a recent article by Ted Underwood and Jordan Sellers (Underwood & Sellers 2016) into a computational narrative—echoing Knuth’s literate programming (1984)—to be critically analyzed and annotated. This method is intimately intertwined with the Jupyter Notebook platform, which allows for the composition of scholarly and scientific inscriptions that are simultaneously human and machine readable. The Notebook is both a document format and a platform for mixing code and prose into executable objects. We have extracted Underwood and Seller’s code and defactored it into a Jupyter Notebook, available at https://github.com/interedition/paceofchange. This means we have recombined code from disparate files, linearized the execution path, demodularized function calls, and annotated code blocks with our own expository comments. As an annotated Notebook we can now engage Underwood and Seller’s code directly as a scholarly inscription and more deeply interrogate the role of data, algorithms, and code in the production of knowledge.\n",
    "\n",
    "After demonstrating the work in the notebook, we will conclude our paper with a critical reflection of the reviewing work that was undertaken with it. We identify the applicability, feasibility, benefits, and drawbacks of this specific approach. We also outline some possible future directions of research that could further contribute to exploring review methods for code scholarship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Defactor ‘Pace of Change’\n",
    "\n",
    "We are interested in what the process and practice looks like of 'defactoring' code. Defactoring code can be understood as close reading the source code of a particular software. This may serve multiple purposes. The process might be geared towards peer reviewing code, it may be done to understand methodological aspects and implications, it may be used as a tool to disseminate and teach such new methodologies or how to use them. Here we use the process of defactoring to produce what might be the first critical edition of any source code in the domain of digital humanities. We unpack the code that Ted Underwood wrote to do the analysis that was reported on in the article he wrote together with Jordan Sellers *How Quickly Do Literary Standards Change?* (Underwood, T. & Sellers, J., 2015. *How Quickly Do Literary Standards Change?* Available at: https://figshare.com/articles/How_Quickly_Do_Literary_Standards_Change_/1418394\n",
    "\n",
    "The code that we are  going to defactor can be found in the Github repository where Underwood open sourced it: https://github.com/tedunderwood/paceofchange\n",
    "\n",
    "There is no given definition of 'defactoring' or its practice. We expect there to be some agreement about the aim and purpose of the process (that can be broadly understood as attempting to understand what a particular piece of code is doing). How this process of understanding is implemented is not prescribed and may take many forms. A potential approach is simply 'using the code' in similar analytic processes, however that would not generate much insights into the actual code that in that case is treated as a black box. Backward engineering where one—in th most narrow understanding of this tactic to unpack code—tries to estimate what code is doing by comparing input and output may give some more insights. Writing automated tests that gauge the different responses to input might yet be another approach. Here however we are interested in a deep and intimate understanding of code [Frabretti 2012] to understand how it is adding or changing methodology and how it could be critiqued. For this we think meticulously deconstructing the code—which it allows us to do as it is open source—works best. \n",
    "\n",
    "Code is made up of instructions that are knit together in a process that may included repetition and process paths that branch out and merge back into a main process. Even fairly simple code may thus result in a 'garden of forking paths' that allows for a combinatorial explosion of possible paths that could be walked. It would require a book-sized examination to do full justice to the code and all its possible execution pathways. Even though Underwood's code is not even particular long in comparison to other code bases, there are multiple potential pathways and various choices as to what data to use, liek rivers and tributaries of data and computation. To fully realize defactoring as a critical method possibly means to explicate all possible routes through some code base. This is certainly infeasble within the scope of this article. It would also require considerable computational hardware and assistance. \n",
    "\n",
    "Thus it is infeasible to represent here *all* execution paths, let alone deeply inspecting them. We chose therefore to deconstruct so that we follow 1 possible execution path through Underwood and Sellers' code that we think presents a good trade off between getting to know the code and actually being able to finish deconstructing it. \n",
    "\n",
    "In technical terms the deconstruction that is presented here is a refactoring of Underwood and Sellers' code so that it can be represented as a single computational list of computing instructions, on in one namespace. Underwood and Sellers purposely divided their code into logical and meaningfull parts, modules, and functions that work together. For a code author this is a means of understanding, keeping track, and controling the process of creating and executing an analysis. We found however that to gain insight in how the code works and especially to narrate and disseminate its working it is useful to refactor the code into what is usually understood as a poor coding practice, namely making it all one single long strongly integrated process. This makes the code resemble more of a linear narrative. We may have stumbled here on a difference between the nature of code and text, or the relative mutual excluding of forms of representation that are in one form, divided and branched, useful to a software developer (to organize a process of analysis), and in another form, linear and narrative, more useful for a human interpreter. What we observed also is that the process of deconstruction literature and code are not symetrical but mirrored. Where deconstruction of literature usually involves it being taking apart into its various components, meanings, and contetualizations, we found that deconstructing softare by defactoring means to get an understanding of the code, its functioning, and meaning by integrating its different and disaparate parts into one single linear computational narrative. Able and 'good practices' informed code, in other words seems already deconstructed (or 'refactored') into modules and composable parts. Underwood and Sellers in this manner deconstructed the problem of analyzing poems with the specific methodology they envisioned. For all practical purposes we effectively are turning well articulated code into sub-optimal code full of 'hacks' and 'code smells'. However, we do think this leverages our ability to understand the narrative that the code also is.\n",
    "\n",
    "We found it useful to intersperes the various logial parts of the code, those parts that seem to handle a clearly bounded 'step' in the algorithmic process, with narrative that reports on how we understood the code and its functioning at that moment of deconstruction. The Jupyter Notebook is a good fit for presenting this exploration of the code. It allows us to present a fully functioning (executable) code path, divided into steps that can be read and commented by us. Reading (and executing along the way) this notebook therefore gives the reader a close resembling of the experience of how we as deconstructionists 'close read' the code.\n",
    "\n",
    "To support ourselves in the reading process (and hopefully also the reader now) we found it useful to keep track of the 'state' of the code as it was executing. We implemented this by listing all the 'active' variables and there values at each step of the process. The explanation of each step is therefore also ammended with a listing of these variables. \n",
    "\n",
    "Integrating code parts that were purposefully decoupled is not without risk of introducing bugs and cripling the code. For instance, if there are two variables with the same name but different function in two distinct codeparts, putting these code parts into one computational narrative will result in these variables conflicting, possibly overwriting one with the other with uncertain results or broken code as a consequence. Luckily the code of Underwood and Sellers was of such composition that we did not run into these kind of troubles and where potential conflict occured it was easy enough to counter it by renaming variables or introducing little bits of helper code that do not change the general signature of the code. We have altered the code written by Underwood and Sellers. The letter is changed in some places, but we contend that the spirit of the work is the same. \n",
    "\n",
    "Remark that the changes and additions we introduced to the code indeed are interpretations and emandations of the code: they are critical interventions just like a textual scholar would undertake, for instance, when critically editing and interpreting a historic text. We do indeed think that the Jupyter Notebook (or rather its content) that is the result of our close examination of Underwood's and Seller's code can be considered the first 'critical edition' of a codebase within the digital humanities. As with firsts, we do realize that our method is probably imperfect and susceptible to many improvements. That however is exactly the purpose of our work here: to explore the valuable and feasible forms of code criticism and its epistemic role in the humanities. [TODO: this needs some STS facing additions too.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is *Defactoring*\n",
    "\n",
    "*Defactoring* is a process or possible a tool for \"[opening the black box](https://en.wikipedia.org/wiki/Blackboxing)\" of computational and data intensive scholarship. It is similar to the process of *[refactoring](https://en.wikipedia.org/wiki/Code_refactoring)* in that we are \"restructuring existing computing code without changing its external behavior.\" Typically, refactoring takes code and bundles it into a separate structure, such as a function or module, to make it more reusable and recombinable. Our efforts here have done just the opposite. We have taken code that was broken up over several functions and files and pulled it into a single, linear narrative. This process invokes *deconstructive* analytic in which we have *internally* vivisected Underwood and Sellers' code, but externally there is little change to the behavior or outputs. These reconfigurations enable us to unpack, drill-down, and dig into the code within the same platform we use to write about the code.\n",
    "\n",
    "Defactoring, as a method of analysis, is deeply imbricated with a technical platform (just as Underwood & Sellers' data, code, and analysis are as well). But rather than pushing the code into a distant repository separate from the prosaic narrative, we compose a *[computational narrative](http://blog.jupyter.org/2015/07/07/project-jupyter-computational-narratives-as-the-engine-of-collaborative-data-science/)* whereby the data, code, and expository text are bundled together. This means we have created a document that can be read by both humans and machines. \n",
    "\n",
    "Such a feat is made possible by the [Jupyter Notebook](http://jupyter.com). The particular [affordances](https://en.wikipedia.org/wiki/Affordance) of the Notebook allow us to weave code, data, and prose together into a single narrative that is simultaneously readable and executable. Given our purpose, to develop a method for critically engaging the code of computational scholarship, it is imperative to foreground Underwood & Sellers' code and Notebooks *afford* a technical mechanism for doing just that.\n",
    "\n",
    "### So what did we do?\n",
    "\n",
    "At a practical level, we have *forked* code from the [git repository](https://github.com/tedunderwood/paceofchange) to create a new *branch* containing this Notebook you are reading now. \n",
    "\n",
    "Underwood and Sellers' have crafted their code such that it relatively easy to replicate their results by simply running a single command. One of the first tasks was to look at the code and follow the path of execution from that initial command. In reading through the code (as contained in multiple `.py` files) we could piece together a rough idea of how Underwood and Sellers' performed their data preparation, normalization, and analysis. However, `.py` files leave much to be desired when it comes to readability and annotateablility. \n",
    "\n",
    "We then copied python code from the various files in the repository into a Jupyter Notebook. Not all of the code in the repository was copied into the notebook for three main reasons. First, not all of the code included in the files is actually needed to replicate the analysis process. The repository includes a bunch of extra code, one could call it \"cruft\", from exploratory analysis or earlier iterations of the analytical process. For example, the file `SonicScrewdiver.py` is never called upon although, based upon the name, we might hypothesize it is an important, catch-all, modules for a variety of different tasks. Other sections of the code, are valid code, but function calls are commented out (such as `binormal_select`) and never executed. We have opted not to include these unused functions or code blocks. Second, not all of the possible execution paths are being analyzed in this Notebook. There six allowable options for slicing the data in `replicate.py`, the entry-point for re-running the analysis. We opted to follow the default, \"full\", which will model the entire dataset. Third, there is a large amount of code that is part of third party libraries, such as the logistic regression implementation that is part of `scikit-learn`, for a multitude of reasons (including practicality) we have decided to \"step over\", and not copy third-party code into this notebook. When trying to follow the path of execution for any program one needs to recognize it is \"[turtles all the way down](https://en.wikipedia.org/wiki/Turtles_all_the_way_down).\" To make our task possible, we have to make a decision about how far down the path of execution the defactoring process will go. We make a decision to focus only on the code written by Underwood and Sellers and leave an analysis of subsequent third-party libraries to a later, and more ambitious, defactoring effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Defactoring code from python files to the notebook](notebook_resources/defactoring.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Underwood and Seller's code is stored within four files, `replicate.py`, `parallel_crossvalidate.py`, `metafilter.py`, and `modlingprocess.py`. Through the process of *defactoring* we have copied|move|transferred|imported code from text files to a Jupyter Notebook. This process has transformed the flow of the code, but not the outputs. \n",
    "\n",
    "In order for the code to execute seamlessly within the notebook, we had to make minor changes and tweaks to the code. These changes fall into 5 categories:\n",
    "\n",
    "* *defactoring functions* - This is the most significant of the changes. When we defactor a function we take the function's code and move it to the global namespace. This has the effect of elimiating the function and just making it part of the main execution path. \n",
    "* *defactoring function calls* - When a function has been defactored, it can no longer be called since there is no explicit definitional code.\n",
    "* *defactoring definitions* - Not all functions can be fully defactored. Functions that are called more than once or those that are short have been kept as re-usable functions. Defactoring Definition cells define the functions above the code cells that use them (preventing errors).\n",
    "* *defactoring namespace* - Because we have defactored some of the functions and their function calls some of the variables in the namespace need to be mapped to eachother. This happens we the return value of a defactored function needs to be stored in a differently named variable.\n",
    "* *defactoring inspections* - When we want to inspect the state of the process, we insert an inspection cell that prints the values of the variables of interest.\n",
    "* *defactoring import* - Because the code is reliant upon external and third party functions, we need to import that code into the global namespace. This cell contains all of those imports.\n",
    "\n",
    "\n",
    "One of the advantages to defactoring a function is it affords us the ability to insert critical commentary (in the form of markdown cells) into the code constituting the function itself. An unfortunate side-effect is that this makes keeping track of one's place in the code a bit difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code expressed below has nine steps:\n",
    "* [Setting Parameters](#Setting-Parameters) - Specifies parameters for the loading, cleaning, and labeling of data as well as sets conditions for the logistic regression.\n",
    "* [Preparing Metadata](#Preparing-MetaData) - Generates a list of *.tsv files from the `poems/` directory. \n",
    "    * [Cleaning Metadata](#Cleaning-Metadata) - Loads the metadata file, `poemetadata.csv` and performs some cleaning of the metadata to make labeling easier.\n",
    "    * [Sorting Data](#Sorting-Data) - Sort the volumes into two bins, reviewed and not reviewed using the cleaned metadata.\n",
    "* [Transforming Words into Features](#Transforming-Words-into-Features) - Identifies the 3,200 most common words in the corpus. Those most common words will be the features for the regression.\n",
    "    * [Filtering Authors](#Filtering-Authors) - Removes poems by authors who have been reviewed.\n",
    "    * [Filtering Words](#Filtering-Words) - Remove any words from the poem data that are not in the most-common feature list.\n",
    "* [Training Predictive Models](#Training-Predictive-Models) - Run a separate logistic regression for each volume, using a single volume as held-out data and measure each model's predictive power.\n",
    "* [Modeling Coefficients](#Modeling-Coefficients) - Run a single logistic regression over all the data to inspect the salient coefficients.\n",
    "* [Saving Output](#Saving-Output) - Save the results of the predictions and the coefficents to disk as CSV files.\n",
    "* [Plotting Results](#Plotting Results) - Generate a plot showing the accuracy of the predictive models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data\n",
    "\n",
    "\n",
    "Before we dive into the code, we had a question about \"what do they mean by *volume*?\" in the Pace of Change article.\n",
    "\n",
    "The answer, to be confirmed, lives in the [Understanding Genre in a Collection of a Million Volumes](https://figshare.com/articles/Understanding_Genre_in_a_Collection_of_a_Million_Volumes_Interim_Report/1281251). Basically, the idea of \"volume\" comes from the Hathi Trust.\n",
    "\n",
    "\n",
    "\n",
    "Volume is equivalent to book. Volume is the Hathi Trust unit. \n",
    "\n",
    "> We worked with HathiTrust, which contains the aggregated collections of large public and university libraries; in the period we’re considering (1820-1919), that gave us a collection of roughly 758,400 books in English, of which about 53,200 include significant amounts of poetry. This doesn’t exhaustively cover print culture; it’s still a sample, with particular selection biases. (page 5)\n",
    "\n",
    "It would seem the 53,200 number comes from the fact that Ted has page level genre information. The details of this can be found in an additional figshare repository, [Page-leve genre metadata](https://figshare.com/articles/Page_Level_Genre_Metadata_for_English_Language_Volumes_in_HathiTrust_1700_1922/1279201) where:\n",
    "\n",
    "> Volumes of pentry often include proce introduction, or front and back matter; this was trimmed using publicly-available metadata. (page 33)\n",
    "\n",
    "This is how he was able to extract individual poems from the Hathi Trust data.\n",
    "\n",
    "TODO: We are going to need to be a bit more formal about how we represent the processes that created the data used in this code.\n",
    "\n",
    "Joris and Matt had short discussion the potential for confounds in the *random* sample which might have skewed that sample because it had the potential to include reviewed poetry. Pages 33 and 34 for the Pace of Change talk about the sampling and data preparation. We needed to talk through exactly what they did to understand it fully. After our discussion we agreed with their reasoning, but we would have liked to see a few more numbers. For example, \n",
    "\n",
    "> when a stray volume from the random set turns up near the top of our model’s list of books likely to be reviewed, it does turn out that many of those authors are reasonably well-known (Rupert Brooke, Elaine Goodale Eastman). (page 33)\n",
    "\n",
    "We would like to see more supporting data about the ratio between well-known and not-well-known authors popping up at the top of the model's list of books. Perhaps this is splitting hairs, but it would be good to have this supporting data. This however raises the question about how to formalize the \"well-knownness\" of a particular author. This utlimately might be more of a commentary upon our total ignorance of 19th century poetry, Matt and Joris are not English literary scholars (Joris is a Dutch literary scholar) and as such neither of us know very much about 19th century poets. Basically, we don't know much about Rupert Brooke and Elaine Goodale Eastman. This is perhaps a minor nitpick.\n",
    "\n",
    "Our question is \"How many *well-known* authors were in the random sample?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the shape of the data\n",
    "\n",
    "The poems live in the `poems` directory. We extracted the first 20 lines of the file \"dul1.ark+=13960=t5fb5xg2z.poe.tsv\" to give a feel what they look like. Basically they represent the vocabulary frequency lists of each poem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\t2745\r\n",
      "the\t1445\r\n",
      "and\t1182\r\n",
      ".\t672\r\n",
      "of\t468\r\n",
      "to\t442\r\n",
      ":\t386\r\n",
      "in\t384\r\n",
      ";\t324\r\n",
      "a\t253\r\n",
      "but\t228\r\n",
      "his\t223\r\n",
      "he\t218\r\n",
      "|'s|\t211\r\n",
      "with\t198\r\n",
      "—\t197\r\n",
      "that\t188\r\n",
      "on\t187\r\n",
      "they\t172\r\n",
      "for\t171\r\n"
     ]
    }
   ],
   "source": [
    "!head -n20 poems/dul1.ark+\\=13960\\=t5fb5xg2z.poe.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we see are the token (not just word, but punctuation too) frequences for the volume. For this particular document, there are 2,745 commas, 1445 instances of the word `the`, and 1182 instances of the word `and`. \n",
    "\n",
    "In addition to data in the files in the `poems/` directory, there is a file, `poemeta.csv` that stores the metadata about each of the volumes. We can look at the first two lines of that file to see the headers and the first row of the data to see what the data points look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docid,actualdate,inferreddate,firstpub,recept,recordid,OCLC,author,imprint,enumcron,title,pubrev,judge,impaud,yrrev,pubname,birth,gender,nationality,othername,notes,canon\r\n",
      "loc.ark+=13960=t8sb4zz1q,1921,1921,1921,addcanon,537314,,\"Lawrence, D. H.\",New York;T. Seltzer;1921.,,Tortoises,,,,,,1885,m,uk,,,y\r\n"
     ]
    }
   ],
   "source": [
    "!head -n2 poemeta.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is the list of column headers of the metadata file, we can infer what they mean based upon their title, but there is no data dictionary to explicitly describe what these headers mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving into the Code\n",
    "\n",
    "We know that `replicate.py` will be our main entry-point for this analysis because the README tells us to replicate the analysis we should run the command:\n",
    "\n",
    "> python3 replicate.py full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will do below is copy the code from `replicate.py` into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DEFACTORING IMPORT\n",
    "import os\n",
    "import csv \n",
    "import random \n",
    "from collections import Counter \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from multiprocessing import Pool \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note to the reader. If you see a red warning box don't fret, this is a by-product of our effort to Dockerize this analysis. Hopefully this will someday go away.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Parameters\n",
    "\n",
    "So this is not exact copy of replicate.py, instead we have *defactored* the code by starting at the branch point at line 45 of replicate.py (git commit e2b5b8f9a86d3f80360865a6628488619f7849d6). Basically everything after `if command == 'full':` and before `elif command == 'quarters':` \n",
    "\n",
    "MJ: The 'rest' of this module basically splits of 6 branches of the process related to the six possible ways of carving up the data `{\"full\", \"quarters\", \"nations\", \"genders\", \"canon\", \"halves\"}`, each option sets the different paramaters for the analytic process associated with that specific command. \n",
    "\n",
    "For reasons of feasibility we will only examine the first branching off tied to the command 'full'.\n",
    "'Full' means: \n",
    "> process all 700 volumes model represented in Fig. 1 of the article \n",
    "\n",
    "(cf. \"model the full 700-volume dataset using default settings\" above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PATHS.\n",
    "\n",
    "sourcefolder = 'poems/'\n",
    "extension = '.poe.tsv'\n",
    "classpath = 'poemeta.csv'\n",
    "outputpath = 'mainmodelpredictions.csv'\n",
    "\n",
    "## EXCLUSIONS.\n",
    "\n",
    "excludeif = dict()\n",
    "excludeif['pubname'] = 'TEM'\n",
    "# We're not using reviews from Tait's.\n",
    "\n",
    "excludeif['recept'] = 'addcanon'\n",
    "# We don't ordinarily include canonical volumes that were not in either sample.\n",
    "# These are included only if we're testing the canon specifically.\n",
    "\n",
    "excludeifnot = dict()\n",
    "excludeabove = dict()\n",
    "excludebelow = dict()\n",
    "\n",
    "excludebelow['firstpub'] = 1700\n",
    "excludeabove['firstpub'] = 1950\n",
    "sizecap = 360\n",
    "\n",
    "# For more historically-interesting kinds of questions, we can limit the part\n",
    "# of the dataset that gets TRAINED on, while permitting the whole dataset to\n",
    "# be PREDICTED. (Note that we always exclude authors from their own training\n",
    "# set; this is in addition to that.) The variables futurethreshold and\n",
    "# pastthreshold set the chronological limits of the training set, inclusive\n",
    "# of the threshold itself.\n",
    "\n",
    "## THRESHOLDS\n",
    "\n",
    "futurethreshold = 1925\n",
    "pastthreshold = 1800\n",
    "\n",
    "# CLASSIFY CONDITIONS\n",
    "\n",
    "positive_class = 'rev'\n",
    "category2sorton = 'reviewed'\n",
    "datetype = 'firstpub'\n",
    "numfeatures = 3200\n",
    "regularization = .00007\n",
    "\n",
    "\n",
    "paths = (sourcefolder, extension, classpath, outputpath)\n",
    "exclusions = (excludeif, \n",
    "              excludeifnot, \n",
    "              excludebelow, \n",
    "              excludeabove, \n",
    "              sizecap)\n",
    "thresholds = (pastthreshold, \n",
    "              futurethreshold)\n",
    "classifyconditions = (category2sorton, \n",
    "                      positive_class, \n",
    "                      datetype, \n",
    "                      numfeatures, \n",
    "                      regularization)\n",
    "\n",
    "### DEFACTORING FUNCTION CALL\n",
    "### rawaccuracy, allvolumes, coefficientuples = pc.create_model(paths, exclusions, thresholds, classifyconditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell above is the specification of a bunch of parameters. These parameters are a set of buttons and knobs which are used to tweak the performance and execution of the computational modeling process. For example, an important variable in the cell above is `regularization` since it specifies the regularization parameter for the logistic regression. What is not well documented here, is why the value .00007 was chosen over other values. \n",
    "\n",
    "The last line in the code cell above, which we have documented with the comment `DEFACTORING FUNCTION CALL` is the point in replicate.py where the script calls out to a function, `create_model()` in a separate file, `parallel_crossvalidate.py`. As part of the defactoring method we draw in the `create_model()` function to incorporate it into our computational narrative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('poems/', '.poe.tsv', 'poemeta.csv', 'mainmodelpredictions.csv')\n",
      "({'recept': 'addcanon', 'pubname': 'TEM'}, {}, {'firstpub': 1700}, {'firstpub': 1950}, 360)\n",
      "(1800, 1925)\n",
      "('reviewed', 'rev', 'firstpub', 3200, 7e-05)\n"
     ]
    }
   ],
   "source": [
    "### DEFACTORING INSPECTION\n",
    "### what are the values being passed to create_model\n",
    "print(paths)\n",
    "print(exclusions)\n",
    "print(thresholds)\n",
    "print(classifyconditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Metadata\n",
    "\n",
    "The code below captures the `create_model()` function, which does computational work that we don't want to *step over* because it is the documentation of Underwood and Seller's analysis. We don't want to treat it as a black box, we want to open it up. So the code cells below *step into* the function and explore its contents in the notebook's global namespace.\n",
    "\n",
    "What is important to recognize about this block of code is that it is only executed once (in our tracing of an execution path), so its decomposition from a function and into the notebook doesn't cause problems with execution. There will be other functions in the narrative below that cannot be fully defactored, because they are repeatedly executed or are part of other python libraries not written by Underwood and Sellers. Those written by Underwood and Sellers are documented in the notebook and those part of other libraries are imported but remain undocumented.\n",
    "\n",
    "Given the size and complexity of the `create_model()` function, the code has broken up over a series of cells to allow for critical discussion of the computational work being executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DEFACTORING FUNCTION\n",
    "### def create_model(paths, exclusions, thresholds, classifyconditions):\n",
    "''' This is the main function in the module.\n",
    "It can be called externally; it's also called\n",
    "if the module is run directly.\n",
    "'''\n",
    "verbose = False\n",
    "\n",
    "if not sourcefolder.endswith('/'):\n",
    "    sourcefolder = sourcefolder + '/'\n",
    "\n",
    "# This just makes things easier.\n",
    "\n",
    "# Get a list of files.\n",
    "allthefiles = os.listdir(sourcefolder)\n",
    "# random.shuffle(allthefiles)\n",
    "\n",
    "volumeIDs = list()\n",
    "volumepaths = list()\n",
    "\n",
    "for filename in allthefiles:\n",
    "\n",
    "    if filename.endswith(extension):\n",
    "        volID = filename.replace(extension, \"\")\n",
    "        # The volume ID is basically the filename minus its extension.\n",
    "        # Extensions are likely to be long enough that there is little\n",
    "        # danger of accidental occurrence inside a filename. E.g.\n",
    "        # '.fic.tsv'\n",
    "        path = sourcefolder + filename\n",
    "        volumeIDs.append(volID)\n",
    "        volumepaths.append(path)\n",
    "        \n",
    "### DEFACTORING FUNCTION CALL\n",
    "### metadict = metafilter.get_metadata(classpath, volumeIDs, excludeif, excludeifnot, excludebelow, excludeabove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code assembles a list of volume identifiers (`volumeIDs`) and file paths (`volumepaths`) by readings the directory listing of files in the `poems/` directory (`sourcefolder`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poemeta.csv\n",
      "['dul1.ark+=13960=t5fb5xg2z', 'dul1.ark+=13960=t75t4h116', 'dul1.ark+=13960=t84j19z0d', 'ellisbell1848', 'emilydickinson', 'gerardmhopkins1918', 'hardywessexpoems1898', 'hvd.32044010164861', 'hvd.32044018706432', 'hvd.32044020453569']\n",
      "{'recept': 'addcanon', 'pubname': 'TEM'}\n",
      "{}\n",
      "{'firstpub': 1700}\n",
      "{'firstpub': 1950}\n"
     ]
    }
   ],
   "source": [
    "### DEFACTORING INSPECTION\n",
    "### what are the values of the variables being passed to get_metadata()\n",
    "### TODO: write a function that when given a list of variables, prints out their name & values\n",
    "print(classpath)\n",
    "print(volumeIDs[0:10]) # this is a long list so only showing the first 10 values\n",
    "print(excludeif)\n",
    "print(excludeifnot)\n",
    "print(excludebelow)\n",
    "print(excludeabove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Metadata\n",
    "\n",
    "Before we can fully dive into the code contents of the `get_metadata()` function, we need to define a couple helper functions. These small functions perform some minor data transformations that are repeatedly used in the `get_metadata()` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEFACTORING FUNCTION DEFINITION\n",
    "### we need these helper functions for execute the next code cell\n",
    "\n",
    "def dirty_pairtree(htid):\n",
    "    period = htid.find('.')\n",
    "    prefix = htid[0:period]\n",
    "    postfix = htid[(period+1): ]\n",
    "    if '=' in postfix:\n",
    "        postfix = postfix.replace('+',':')\n",
    "        postfix = postfix.replace('=','/')\n",
    "    dirtyname = prefix + \".\" + postfix\n",
    "    return dirtyname\n",
    "\n",
    "def forceint(astring):\n",
    "    try:\n",
    "        intval = int(astring)\n",
    "    except:\n",
    "        intval = 0\n",
    "\n",
    "    return intval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a long block of code that is difficult to break apart because of the `with open` block of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poemeta.csv\n",
      "tossing loc.ark:/13960/t8sb4zz1q\n",
      "tossing mdp.39015013402501\n",
      "tossing mdp.39015011913525\n",
      "tossing hardywessexpoems189.hardywessexpoems1898\n",
      "tossing gerardmhopkins191.gerardmhopkins1918\n",
      "tossing loc.ark:/13960/t3fx82c2q\n",
      "tossing emilydickinso.emilydickinson\n",
      "tossing ellisbell184.ellisbell1848\n",
      "We have 8 volumes in missing in metadata, and\n",
      "0 volumes missing in the directory.\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "### DEFACTORING FUNCTION \n",
    "### def get_metadata(classpath, volumeIDs, excludeif, excludeifnot, excludebelow, excludeabove):\n",
    "'''\n",
    "As the name would imply, this gets metadata matching a given set of volume\n",
    "IDs. It returns a dictionary containing only those volumes that were present\n",
    "both in metadata and in the data folder.\n",
    "\n",
    "It also accepts four dictionaries containing criteria that will exclude volumes\n",
    "from the modeling process.\n",
    "'''\n",
    "print(classpath)\n",
    "metadict = dict()\n",
    "\n",
    "with open(classpath, encoding = 'utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    anonctr = 0\n",
    "\n",
    "    for row in reader:\n",
    "        volid = dirty_pairtree(row['docid'])\n",
    "        theclass = row['recept'].strip()\n",
    "\n",
    "        # I've put 'remove' in the reception column for certain\n",
    "        # things that are anomalous.\n",
    "        if theclass == 'remove':\n",
    "            continue\n",
    "\n",
    "        bail = False\n",
    "        for key, value in excludeif.items():\n",
    "            if row[key] == value:\n",
    "                bail = True\n",
    "        for key, value in excludeifnot.items():\n",
    "            if row[key] != value:\n",
    "                bail = True\n",
    "        for key, value in excludebelow.items():\n",
    "            if forceint(row[key]) < value:\n",
    "                bail = True\n",
    "        for key, value in excludeabove.items():\n",
    "            if forceint(row[key]) > value:\n",
    "                bail = True\n",
    "\n",
    "        if bail:\n",
    "            print(\"tossing \"+volid) ## DEFACTORING CODE\n",
    "            continue\n",
    "\n",
    "        birthdate = forceint(row['birth'])\n",
    "\n",
    "        pubdate = forceint(row['inferreddate'])\n",
    "\n",
    "        gender = row['gender'].rstrip()\n",
    "        nation = row['nationality'].rstrip()\n",
    "\n",
    "        #if pubdate >= 1880:\n",
    "            #continue\n",
    "\n",
    "        if nation == 'ca':\n",
    "            nation = 'us'\n",
    "        elif nation == 'ir':\n",
    "            nation = 'uk'\n",
    "        # I hope none of my Canadian or Irish friends notice this.\n",
    "\n",
    "        notes = row['notes'].lower()\n",
    "        author = row['author']\n",
    "        if len(author) < 1 or author == '<blank>':\n",
    "            author = \"anonymous\" + str(anonctr)\n",
    "            anonctr += 1\n",
    "\n",
    "        title = row['title']\n",
    "        canon = row['canon']\n",
    "\n",
    "        # I'm creating two distinct columns to indicate kinds of\n",
    "        # literary distinction. The reviewed column is based purely\n",
    "        # on the question of whether this work was in fact in our\n",
    "        # sample of contemporaneous reviews. The obscure column incorporates\n",
    "        # information from post-hoc biographies, which trumps\n",
    "        # the question of reviewing when they conflict.\n",
    "\n",
    "        if theclass == 'random':\n",
    "            obscure = 'obscure'\n",
    "            reviewed = 'not'\n",
    "        elif theclass == 'reviewed':\n",
    "            obscure = 'known'\n",
    "            reviewed = 'rev'\n",
    "        elif theclass == 'addcanon':\n",
    "            print(\"this is executing\") ## DEFACTORING CODE\n",
    "            obscure = 'known'\n",
    "            reviewed = 'addedbecausecanon'\n",
    "        else:\n",
    "            print(\"Missing class\" + theclass)\n",
    "\n",
    "        if notes == 'well-known':\n",
    "            obscure = 'known'\n",
    "        if notes == 'obscure':\n",
    "            obscure = 'obscure'\n",
    "\n",
    "        if canon == 'y':\n",
    "            if theclass == 'addcanon':\n",
    "                actually = 'Norton, added'\n",
    "            else:\n",
    "                actually = 'Norton, in-set'\n",
    "        elif reviewed == 'rev':\n",
    "            actually = 'reviewed'\n",
    "        else:\n",
    "            actually = 'random'\n",
    "\n",
    "        metadict[volid] = dict()\n",
    "        metadict[volid]['reviewed'] = reviewed\n",
    "        metadict[volid]['obscure'] = obscure\n",
    "        metadict[volid]['pubdate'] = pubdate\n",
    "        metadict[volid]['birthdate'] = birthdate\n",
    "        metadict[volid]['gender'] = gender\n",
    "        metadict[volid]['nation'] = nation\n",
    "        metadict[volid]['author'] = author\n",
    "        metadict[volid]['title'] = title\n",
    "        metadict[volid]['canonicity'] = actually\n",
    "        metadict[volid]['pubname'] = row['pubname']\n",
    "        metadict[volid]['firstpub'] = forceint(row['firstpub'])\n",
    "\n",
    "# These come in as dirty pairtree; we need to make them clean.\n",
    "\n",
    "cleanmetadict = dict()\n",
    "allidsinmeta = set([x for x in metadict.keys()])\n",
    "allidsindir = set([dirty_pairtree(x) for x in volumeIDs])\n",
    "missinginmeta = len(allidsindir - allidsinmeta)\n",
    "missingindir = len(allidsinmeta - allidsindir)\n",
    "print(\"We have \" \n",
    "      + str(missinginmeta) \n",
    "      + \" volumes in missing in metadata, and\")\n",
    "print(str(missingindir) + \" volumes missing in the directory.\")\n",
    "print(allidsinmeta - allidsindir)\n",
    "\n",
    "for anid in volumeIDs:\n",
    "    dirtyid = dirty_pairtree(anid)\n",
    "    if dirtyid in metadict:\n",
    "        cleanmetadict[anid] = metadict[dirtyid]\n",
    "\n",
    "### DEFACTORING FUNCTION RETURN\n",
    "### return cleanmetadict               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Arnold, Matthew,',\n",
       " 'birthdate': 1822,\n",
       " 'canonicity': 'Norton, in-set',\n",
       " 'firstpub': 1855,\n",
       " 'gender': 'm',\n",
       " 'nation': 'uk',\n",
       " 'obscure': 'known',\n",
       " 'pubdate': 1855,\n",
       " 'pubname': 'ER',\n",
       " 'reviewed': 'rev',\n",
       " 'title': 'Poems'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DEFACTORING INSPECTION\n",
    "### looking up an ID listed earlier\n",
    "cleanmetadict['dul1.ark+=13960=t5fb5xg2z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DEFACTORING NAMESPACE \n",
    "metadict = cleanmetadict  # put the data into the global namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What just happened here? Well, the code above loaded the `poemeta.csv` file and filtered out a bunch of rows (based upon the `excludeif`, `excludeifnot`, `excludeabove`, and `excludebelow` variables) and also normalizes some of the `nation` data (normalizing is a pretty clinical way of lumping Canada with the United States and Ireland with the UK). Nationality is not a factor in the Pace of Change analysis, but it is interesting to see this code here, it implies this code is used in other analyses.\n",
    "\n",
    "The other important thing this code cell does is split the `recept` column in the `poemeta.csv` into two columns, `obscure` and `reviewed`. There is a bit of logic here that we do not fully grasp at this point. From what we can tell from the code and Ted's comment, there poems that are reviewed, there are poems that are obscure, and there are poems that are not in the reviewed set but are never-the-less part of the cannon. This means they are \"known\" and, according to Ted's comment, trumps the conflict when the author is known (`obscure = 'known'`) but not explicitly in the reviewed set. \n",
    "\n",
    "We have discovered after adding some `# DEFACTORING CODE` snippets that this code never actually runs. All of the poems with the 'addcanon' property are tossed out and the conflict, where the poem is known by in the random set, never appears to occur. Conjector: is this a remnant of Ted refactoring the code due to changes in the analysis process or just working with different data or something we cannot possible conceive. What was the author's intent? \n",
    "\n",
    "We know that poems with the 'addcanon' in the 'recept' column are being excluded because they are included in the `excludeif` dictionary. Why? The code in the first code cell provides somewhat of an explanation\n",
    "\n",
    "```\n",
    "excludeif['recept'] = 'addcanon'\n",
    "# We don't ordinarily include canonical volumes that were not in either sample.\n",
    "# These are included only if we're testing the canon specifically.\n",
    "```\n",
    "\n",
    "It should noted we spent a considerable amount of time interpreting the code that handled this particular situation before realizing that it would never be executed because of the settings in the `excludeif` dictionary. That makes us look stupid, but we also now have a more intimate understanding and relationship with the code. or maybe we are still stupid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we have a list of volumes with metadata, we can select the groups of IDs\n",
    "# that we actually intend to contrast. If we want to us more or less everything,\n",
    "# this may not be necessary. But in some cases we want to use randomly sampled subsets.\n",
    "\n",
    "# The default condition here is\n",
    "\n",
    "# category2sorton = 'reviewed'\n",
    "# positive_class = 'rev'\n",
    "# sizecap = 350\n",
    "# A sizecap less than one means, no sizecap.\n",
    "\n",
    "### DEFACTORING FUNCTION CALL\n",
    "### IDsToUse, classdictionary = metafilter.label_classes(metadict, category2sorton, positive_class, sizecap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting Training Data\n",
    "\n",
    "We have DEFACTORED the metafilter.label_classes() function. This function reads the metadata properties and puts all entries into one of two bins: *positive* or *negative*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEFACTORING FUNCTION\n",
    "### def label_classes(metadict, category2sorton, positive_class, sizecap):\n",
    "''' This takes as input the metadata dictionary generated\n",
    "by get_metadata. It subsets that dictionary into a\n",
    "positive class and a negative class. Instances that belong\n",
    "to neither class get ignored.\n",
    "'''\n",
    "\n",
    "all_instances = set([x for x in metadict.keys()])\n",
    "\n",
    "# The first stage is to find positive instances.\n",
    "\n",
    "all_positives = set()\n",
    "\n",
    "for key, value in metadict.items():\n",
    "    if value[category2sorton] == positive_class:\n",
    "        all_positives.add(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the author's code distinguishes the red triangles from the grey dots in figure one. If poem metadata has the value 'rev' for the 'reviewed' property then it is labeled as a positive. The next cell does the same for all negatives and removes any items that were added because of the canon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_negatives = all_instances - all_positives\n",
    "iterator = list(all_negatives)\n",
    "for item in iterator:\n",
    "    if metadict[item]['reviewed'] == 'addedbecausecanon':\n",
    "        all_negatives.remove(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative labels are assigned to all instances that are not in the set of positive instances. There is additional code that filters out anything with 'addedbecausecannon' set for the 'reviewed' property, but this code should never execute. This is a vestige of testing with the canon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "if sizecap > 0 and len(all_positives) > sizecap:\n",
    "    positives = random.sample(all_positives, sizecap)\n",
    "else:\n",
    "    positives = list(all_positives)\n",
    "    print(len(all_positives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we see `360` being printed by the code above we know he is not sampling from the positives list. Ted's comment above, seems to indicate the sizecap is 350, but if you look at the code in the first code cell, the sizecap is *actually* 360...which just so happens to be the number of positive labeled instances. Funny. Looks like Ted updated his sizecap, but didn't update his comment.\n",
    "\n",
    "How was the sizecap determined? Performance and scalability? Perhaps some of the test sets were much larger than 360 instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If there's a sizecap we also want to ensure classes have\n",
    "# matching sizes and roughly equal distributions over time.\n",
    "\n",
    "numpositives = len(all_positives)\n",
    "\n",
    "if sizecap > 0 and len(all_negatives) > numpositives:\n",
    "    if not 'date' in category2sorton:\n",
    "        available_negatives = list(all_negatives)\n",
    "        negatives = list()\n",
    "\n",
    "        for anid in positives:\n",
    "            date = metadict[anid]['pubdate']\n",
    "\n",
    "            available_negatives = sort_by_proximity(available_negatives, \n",
    "                                                    metadict, date)\n",
    "            selected_id = available_negatives.pop(0)\n",
    "            negatives.append(selected_id)\n",
    "\n",
    "    else:\n",
    "        # if we're dividing classes by date, we obvs don't want to\n",
    "        # ensure equal distributions over time.\n",
    "\n",
    "        negatives = random.sample(all_negatives, sizecap)\n",
    "\n",
    "else:\n",
    "    negatives = list(all_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So most of the code in the cell above does not execute because we are not sampling from the positives distribution. \n",
    "\n",
    "This code cell makes an un-excuted reference to a function `sort_by_proximity()` which we are not including because it is not part of the execution path we are documenting in this notebook. This has provoked a conversation about if we should remove the code from the conditional blocks from the notebook. Yet, keeping them maintains the residue of Ted's development and thinking about what he needs to do with the data and in the analysis. \n",
    "\n",
    "These issues point to properties of code that make it difficult to review or critique, that is, we are in this case, reviewing a single execution path of the code, not the code itself. So we are dealing with a *code-criticism conundrum*: What is the required or adequate breadth and depth of the critique? The decision to include or not include `sort_by_proximity()` is a breadth issue. How broad should we be in including code that does not execute? Note, we are including code from a conditional block that doesn't execute, but are not going out the additional step to include non-executed function defined elsewhere in the code. The decision to include or not include code from the standard library, code not written by Ted, is a depth issue. In the code cell above, there are many functions we are *stepping over*, like `len`, `list`, `append`, `pop`, `random.sample`, etc., because they are black-boxed. There is no need to critique or test or inspect those functions because they have been tested and evaluated  thoroughly outside of the scope of Ted's project [We need a strong REF here].\n",
    "\n",
    "Full reflexivity here would also mean that we note that the 'rules of the game' for code criticism aren't quite clear yet and therefore we are possibly feeling our way through an emerging methodological standard of practice for code criticism. As we see vestiges of Ted evolution in thinking in his code, this notebook is capturing the evolution of our thinking about DEFACTORING as a practice. \n",
    "\n",
    "REF: Hiller and Joris about the tension between code's textual and processual dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We have 360 positive, and\n",
      "360 negative instances.\n"
     ]
    }
   ],
   "source": [
    "# Now we have two lists of ids.\n",
    "\n",
    "IDsToUse = set()\n",
    "classdictionary = dict()\n",
    "\n",
    "print()\n",
    "print(\"We have \" + str(len(positives)) + \" positive, and\")\n",
    "print(str(len(negatives)) + \" negative instances.\")\n",
    "\n",
    "for anid in positives:\n",
    "    IDsToUse.add(anid)\n",
    "    classdictionary[anid] = 1\n",
    "\n",
    "for anid in negatives:\n",
    "    IDsToUse.add(anid)\n",
    "    classdictionary[anid] = 0\n",
    "\n",
    "for key, value in metadict.items():\n",
    "    if value['reviewed'] == 'addedbecausecanon':\n",
    "        IDsToUse.add(key)\n",
    "        classdictionary[key] = 0\n",
    "# We add the canon supplement, but don't train on it.\n",
    "\n",
    "### DEFACTORING FUNCTION RETERN\n",
    "### return IDsToUse, classdictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Words into Features\n",
    "\n",
    "\n",
    "Now we return to the execution of the `create_model` function from `parallel_crossvalidate.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEFACTORING FUNCTION DEFINITIONS\n",
    "### We need to define the infer_date function\n",
    "\n",
    "def infer_date(metadictentry, datetype):\n",
    "    if datetype == 'pubdate':\n",
    "        return metadictentry[datetype]\n",
    "    elif datetype == 'firstpub':\n",
    "        firstpub = metadictentry['firstpub']\n",
    "        if firstpub > 1700 and firstpub < 1950:\n",
    "            return firstpub\n",
    "        else:\n",
    "            return metadictentry['pubdate']\n",
    "    else:\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a vocabulary list and a volsize dict\n",
    "wordcounts = Counter()\n",
    "\n",
    "volspresent = list()\n",
    "orderedIDs = list()\n",
    "\n",
    "positivecounts = dict()\n",
    "negativecounts = dict()\n",
    "\n",
    "for volid, volpath in zip(volumeIDs, volumepaths):\n",
    "    if volid not in IDsToUse:\n",
    "        continue\n",
    "    else:\n",
    "        volspresent.append((volid, volpath))\n",
    "        orderedIDs.append(volid)\n",
    "\n",
    "    date = infer_date(metadict[volid], datetype)\n",
    "    if date < pastthreshold or date > futurethreshold:\n",
    "        continue\n",
    "    else:\n",
    "        with open(volpath, encoding = 'utf-8') as f:\n",
    "            for line in f:\n",
    "                fields = line.strip().split('\\t')\n",
    "                if len(fields) > 2 or len(fields) < 2:\n",
    "                    # print(line)\n",
    "                    continue\n",
    "                word = fields[0]\n",
    "                if len(word) > 0 and word[0].isalpha():\n",
    "                    count = int(fields[1])\n",
    "                    wordcounts[word] += 1\n",
    "                    # for initial feature selection we use the number of\n",
    "                    # *documents* that contain a given word,\n",
    "                    # so it's just +=1.\n",
    "\n",
    "vocablist = [x[0] for x in wordcounts.most_common(numfeatures)]\n",
    "\n",
    "# vocablist = binormal_select(vocablist, positivecounts, negativecounts, totalposvols, totalnegvols, 3000)\n",
    "# Feature selection is deprecated. There are cool things\n",
    "# we could do with feature selection,\n",
    "# but they'd improve accuracy by 1% at the cost of complicating our explanatory task.\n",
    "# The tradeoff isn't worth it. Explanation is more important.\n",
    "# So we just take the most common words (by number of documents containing them)\n",
    "# in the whole corpus. Technically, I suppose, we could crossvalidate that as well,\n",
    "# but *eyeroll*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "['all', 'is', 'at', 'a', 'in', 'the', 'on', 'to', 'for', 'as', 'i', 'but', 'that', 'with', 'by', 'of', 'not', 'and', 'who', 'it', 'his', 'be', 'when', 'from', 'one', 'they', 'he', 'like', 'or', 'now', 'was', 'their', 'no', 'this', 'have', 'so', 'we', 'them', 'see', 'its', 'there', 'where', 'her', 'will', 'are', 'then', 'were', 'heart', 'our', 'an']\n"
     ]
    }
   ],
   "source": [
    "### DEFACTORING INSPECTION\n",
    "### What is in the vocablist variable?\n",
    "print(len(vocablist))\n",
    "print(vocablist[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an important section of code because it contains the code for the selection of the 3200 word-features, or \"variables\" as he calls them on page 35 (the methodology appendix), used in the logistic regression. Most notable is the code that has been commented out at the very end of the block. The heuristic for feature selection was simply to select the 3200 most common words, a simple and easy to explain technique (also easy to implement with Python's Counter collection). The comment discusses an alternative feature selection technique using binormal selection which he has implemented in the function `binormal_selection`. Because this code is commented out, we do not explore it in-depth here. More interesting is the rationale about *why* it has been commented out:\n",
    "\n",
    "> There are cool things we could do with feature selection, but they'd improve accuracy by 1% at the cost of complicating our explanatory task.\n",
    "\n",
    "What we are seeing in this comment is a road not taken, which normally the DEFACTORING method would ignore, but the code, the comment, and the implications are crucially important. This reveals much about about Ted's reasoning on the effort and energy he wishes to invest in *explaining* method. There is judgment about the expertise of his audience. This points to a crucial problem at the intersection of humanities and computer science where the dissemination of description of statistical methods are inhibiting or hindering the full realization of the epistemlogical richness of computation as a method of inquiry. Ted is holding himself back, a form of self-censorship, because of a perceived Audience That cannot understand a binormal feature selection technique without a significant amount of work to explain its epistomolgical implications. \n",
    "\n",
    "We think this snippet of code is significant and justifies our method because it is only through close code review were we able to uncover these traces of Ted's thinking and experimentation. We can see epistomolary roads not taken because of strenuous dialectical relationship between the computational potentiality and the disciplinary acceptability. \n",
    "\n",
    "There is more for us to say and think about this vinette. But we need to move on.\n",
    "\n",
    "Aside: we couldn't help ourselves and did a little digging into the `binormal_selection` function. There is an oblique reference to \"see forman\" which we think refers to George Forman who has written several articles on feature selection in texts. We should confirm with Ted.\n",
    "- http://dl.acm.org/citation.cfm?id=944974\n",
    "- http://link.springer.com/chapter/10.1007%2F3-540-45681-3_13\n",
    "- We think this is the paper: http://www.hpl.hp.com/techreports/2007/HPL-2007-32R1.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "donttrainon = list()\n",
    "\n",
    "# Here we create a list of volumed IDs not to be used for training.\n",
    "# For instance, we have supplemented the dataset with volumes that\n",
    "# are in the Norton but that did not actually occur in random\n",
    "# sampling. We want to make predictions for these, but never use\n",
    "# them for training.\n",
    "\n",
    "for idx1, anid in enumerate(orderedIDs):\n",
    "    reviewedstatus = metadict[anid]['reviewed']\n",
    "    date = infer_date(metadict[anid], datetype)\n",
    "    if reviewedstatus == 'addedbecausecanon':\n",
    "        donttrainon.append(idx1)\n",
    "    elif date < pastthreshold or date > futurethreshold:\n",
    "        donttrainon.append(idx1)\n",
    "\n",
    "authormatches = [list(donttrainon) for x in range(len(orderedIDs))]\n",
    "# For every index in authormatches, identify a set of indexes that have\n",
    "# the same author. Obvs, there will always be at least one.\n",
    "\n",
    "# Since we are going to use these indexes to exclude rows, we also add\n",
    "# all the ids in donttrainon to every volume\n",
    "\n",
    "for idx1, anid in enumerate(orderedIDs):\n",
    "    thisauthor = metadict[anid]['author']\n",
    "    for idx2, anotherid in enumerate(orderedIDs):\n",
    "        otherauthor = metadict[anotherid]['author']\n",
    "        if thisauthor == otherauthor and not idx2 in authormatches[idx1]:\n",
    "            authormatches[idx1].append(idx2)\n",
    "\n",
    "for alist in authormatches:\n",
    "    alist.sort(reverse = True)\n",
    "\n",
    "# I am reversing the order of indexes so that I can delete them from\n",
    "# back to front, without changing indexes yet to be deleted.\n",
    "# This will become important in the modelingprocess module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "### DEFACTORING INSPECTION\n",
    "### What volumes are we not training on?\n",
    "print(donttrainon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is blank, what this tells us is all volumes are being used in the training. Lets inspect a few more variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "720\n",
      "[582, 499, 420, 368, 200, 7]\n",
      "[582, 499, 420, 368, 200, 7]\n",
      "uc2.ark+=13960=t3fx7436h\n",
      "uc1.b4104728\n",
      "{'reviewed': 'rev', 'pubname': 'ER', 'birthdate': 1809, 'obscure': 'known', 'pubdate': 1861, 'gender': 'm', 'firstpub': 1849, 'canonicity': 'Norton, in-set', 'title': 'In memoriam', 'author': 'Tennyson, Alfred Tennyson,', 'nation': 'uk'}\n",
      "{'reviewed': 'rev', 'pubname': 'WR', 'birthdate': 1809, 'obscure': 'known', 'pubdate': 1859, 'gender': 'm', 'firstpub': 1859, 'canonicity': 'Norton, in-set', 'title': 'Idyls of the King', 'author': 'Tennyson, Alfred Tennyson,', 'nation': 'uk'}\n"
     ]
    }
   ],
   "source": [
    "### DEFACTORING INSPECTION\n",
    "print(len(orderedIDs))\n",
    "print(len(authormatches))\n",
    "print(authormatches[7])\n",
    "print(authormatches[582])\n",
    "print(orderedIDs[582])\n",
    "print(orderedIDs[499])\n",
    "print(metadict['uc2.ark+=13960=t3fx7436h'])\n",
    "print(metadict['uc1.b4104728'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all rote data preparation. The authors compile a list that shouldn't be used as training data if the date is incorrect or if the books are part of the \"addedbecauseofcanon\" class (representing a well known author). From this list they compile a list of authors who have been reviewed and then removing their other works from the list. \n",
    "\n",
    "The inspection code above was necessary for us to understanding the complicated data structure they created.\n",
    "\n",
    "The list `authormatches` is a list of all the poems and each is a list of other poems by the same author. Essentially this data structure is describing the relations of each poem to other poems, that relation being \"other poems by the same author\". It took us a bit of work to figure out because all of this is obscured by the fact the relations are expressed by list indexes. We are working with abstractions which we assume are important for the `modelingprocess` which is invoked below.\n",
    "\n",
    "The purpose of this is because\n",
    "\n",
    "> ...we did exclude who were already in our reviewed sample for a given genre. (page 34)\n",
    "\n",
    "What we seen in the code is the necessary steps to be able to exclude author already in the reviewed sample, but we don't yet see any reference to genre. Either this is implicit (because all these data are the same genre, poetry) or hasn't been addressed as of yet in the code.\n",
    "\n",
    "Aside: we should try an annotate the author's narrative in the article to point to the specific moments in the code where he is describing (in english) what is happening in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEFACTORING DEFINITIONS\n",
    "\n",
    "usedate = False\n",
    "# Leave this flag false unless you plan major\n",
    "# surgery to reactivate the currently-deprecated\n",
    "# option to use \"date\" as a predictive feature.\n",
    "\n",
    "def get_features(wordcounts, wordlist):\n",
    "    numwords = len(wordlist)\n",
    "    wordvec = np.zeros(numwords)\n",
    "    for idx, word in enumerate(wordlist):\n",
    "        if word in wordcounts:\n",
    "            wordvec[idx] = wordcounts[word]\n",
    "\n",
    "    return wordvec\n",
    "\n",
    "# In an earlier version of this script, we sometimes used\n",
    "# \"publication date\" as a feature, to see what would happen.\n",
    "# In the current version, we don't. Some of the functions\n",
    "# and features remain, but they are deprecated. E.g.:\n",
    "\n",
    "def get_features_with_date(wordcounts, wordlist, date, totalcount):\n",
    "    numwords = len(wordlist)\n",
    "    wordvec = np.zeros(numwords + 1)\n",
    "    for idx, word in enumerate(wordlist):\n",
    "        if word in wordcounts:\n",
    "            wordvec[idx] = wordcounts[word]\n",
    "\n",
    "    wordvec = wordvec / (totalcount + 0.0001)\n",
    "    wordvec[numwords] = date\n",
    "    return wordvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_features` simply takes the wordcounts from the parsed poem and filters out any words that are not part of `wordlist` which is the selected features described above.\n",
    "\n",
    "Note, we are `including get_features_with_date` even though it is not called beacuse it is part of Underwood and Seller's comment narrative above. While it is present in the code below it is never called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volsizes = dict()\n",
    "voldata = list()\n",
    "classvector = list()\n",
    "\n",
    "for volid, volpath in volspresent:\n",
    "\n",
    "    with open(volpath, encoding = 'utf-8') as f:\n",
    "        voldict = dict()\n",
    "        totalcount = 0\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) > 2 or len(fields) < 2:\n",
    "                continue\n",
    "\n",
    "            word = fields[0]\n",
    "            count = int(fields[1])\n",
    "            voldict[word] = count\n",
    "            totalcount += count\n",
    "\n",
    "    date = infer_date(metadict[volid], datetype)\n",
    "    date = date - 1700\n",
    "    if date < 0:\n",
    "        date = 0\n",
    "\n",
    "    if usedate:\n",
    "        features = get_features_with_date(voldict, \n",
    "                                          vocablist, \n",
    "                                          date, \n",
    "                                          totalcount)\n",
    "        voldata.append(features)\n",
    "    else:\n",
    "        features = get_features(voldict, vocablist)\n",
    "        voldata.append(features / (totalcount + 0.001))\n",
    "\n",
    "\n",
    "    volsizes[volid] = totalcount\n",
    "    classflag = classdictionary[volid]\n",
    "    classvector.append(classflag)\n",
    "\n",
    "data = pd.DataFrame(voldata)\n",
    "\n",
    "sextuplets = list()\n",
    "for i, volid in enumerate(orderedIDs):\n",
    "    listtoexclude = authormatches[i]\n",
    "    asixtuple = (data, \n",
    "                 classvector, \n",
    "                 listtoexclude, \n",
    "                 i, \n",
    "                 usedate, \n",
    "                 regularization)\n",
    "    sextuplets.append(asixtuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code opens up each of the files in the poems/ directory, parses the file, does some data cleaning with respect to the structure of those files and with dates of poems older than 1700 (this is probably vestage code because we are not using date as a predictive feature. The important bit is the call to the `get_features` function which throws out the word features that are not part of the list of selected word features as determined by the `most_common()` call above and stored in the `vocablist` variable. \n",
    "\n",
    "\n",
    "We are curious about this code:\n",
    "\n",
    "```\n",
    "voldata.append(features / (totalcount + 0.001))\n",
    "```\n",
    "\n",
    "We understand he is normalizing the data to make volumes of differing sizes comparable. Turning absolute frequencies into relative frequencies. However, we don't know why he is adding 0.001 to the total count. Is this to prevent a potential divide by zero? NOTE: we think that the 0.001 is added so the logistic regression doesn't result in infinite at zero when running the cost function.\n",
    "\n",
    "Sextuplets is a list of tuples with six values. This is the datastructure which will be passed to the modeling process. Each row of `sextuplets` contains all of the necessary data structures to model each poem. because we are generating a new model for each poem, we need to pass a couple parameters to the modeling process (such as which poems to ignore because they are by the same author, `listtoexclude`, when modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick investigation of the six key datastructures\n",
    "\n",
    "The modeling function described in the next section of the notebook relies upon six data structures from \n",
    "\n",
    "- data: a document features matrix. Word features are the columns and volumes are the rows. 720 x 3200\n",
    "- classvector: the classification of documents as either 'reviewed' (1) or 'random' (0).\n",
    "- listtoexclude: the list of poems to ignore because they are the same author\n",
    "- i: the index of the volume\n",
    "- usedate: a flag indicating if date is a feature. It is false in the default execution path.\n",
    "- regularization: a parameter for the scikit-learn LogisticRegression function. hardcoded parameter from the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1         2         3         4         5         6     \\\n",
      "0  0.004799  0.005708  0.002581  0.009198  0.013961  0.052534  0.006799   \n",
      "1  0.004145  0.006467  0.003084  0.009484  0.013928  0.051733  0.005472   \n",
      "2  0.001781  0.010095  0.006532  0.013658  0.013658  0.049881  0.002969   \n",
      "3  0.001175  0.002776  0.002401  0.017079  0.008302  0.042335  0.004751   \n",
      "4  0.005599  0.001786  0.003620  0.012671  0.011995  0.037674  0.005768   \n",
      "\n",
      "       7         8         9       ...         3190      3191      3192  \\\n",
      "0  0.016069  0.006217  0.003417    ...     0.000036  0.000036  0.000036   \n",
      "1  0.014558  0.004510  0.003349    ...     0.000033  0.000033  0.000033   \n",
      "2  0.020190  0.007126  0.004157    ...     0.000000  0.000000  0.000000   \n",
      "3  0.014753  0.006626  0.003351    ...     0.000225  0.000000  0.000000   \n",
      "4  0.016001  0.005551  0.006372    ...     0.000048  0.000024  0.000000   \n",
      "\n",
      "       3193      3194      3195      3196      3197      3198      3199  \n",
      "0  0.000036  0.000036  0.000036  0.000000  0.000000  0.000109  0.000036  \n",
      "1  0.000000  0.000033  0.000000  0.000000  0.000033  0.000000  0.000000  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3  0.000000  0.000025  0.000050  0.000025  0.000000  0.000000  0.000025  \n",
      "4  0.000000  0.000000  0.000000  0.000097  0.000048  0.000000  0.000024  \n",
      "\n",
      "[5 rows x 3200 columns]\n",
      "[1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "[582, 499, 420, 368, 200, 7]\n",
      "582\n",
      "False\n",
      "7e-05\n"
     ]
    }
   ],
   "source": [
    "### DEFACTORING INSPECTION\n",
    "print(sextuplets[582][0].head()) #data\n",
    "print(sextuplets[582][1]) #classvector \n",
    "print(sextuplets[582][2]) #listtoexclude\n",
    "print(sextuplets[582][3]) #i\n",
    "print(sextuplets[582][4]) #usedate\n",
    "print(sextuplets[582][5]) #regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Predictive Models\n",
    "\n",
    "We are now about to step down into the very heart of the project, the modeling of each individual text.\n",
    "\n",
    "To do this we need to bring the function, model_one_volume into the global namespace of the notebook. This means we need to dig into a new module, modelingprocess and extract a few functions from it. The main modeling functin, `model_one_volume` depends upon two helper functions, `normalizearray()` and `sliceframe.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEFACTORING DEFINITION\n",
    "\n",
    "# modelingprocess.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def sliceframe(dataframe, yvals, excludedrows, testrow):\n",
    "    numrows = len(dataframe)\n",
    "    newyvals = list(yvals)\n",
    "    for i in excludedrows:\n",
    "        del newyvals[i]\n",
    "        # NB: This only works if we assume that excluded rows\n",
    "        # has already been sorted in descending order !!!!!!!\n",
    "        # otherwise indexes will slide around as you delete\n",
    "\n",
    "    trainingset = dataframe.drop(dataframe.index[excludedrows])\n",
    "\n",
    "    newyvals = np.array(newyvals)\n",
    "    testset = dataframe.iloc[testrow]\n",
    "\n",
    "    return trainingset, newyvals, testset\n",
    "\n",
    "def normalizearray(featurearray, usedate):\n",
    "    '''Normalizes an array by centering on means and\n",
    "    scaling by standard deviations. Also returns the\n",
    "    means and standard deviations for features.\n",
    "    '''\n",
    "\n",
    "    numinstances, numfeatures = featurearray.shape\n",
    "    means = list()\n",
    "    stdevs = list()\n",
    "    lastcolumn = numfeatures - 1\n",
    "    for featureidx in range(numfeatures):\n",
    "\n",
    "        thiscolumn = featurearray.iloc[ : , featureidx]\n",
    "        thismean = np.mean(thiscolumn)\n",
    "\n",
    "        thisstdev = np.std(thiscolumn)\n",
    "\n",
    "        if (not usedate) or featureidx != lastcolumn:\n",
    "            # If we're using date we don't normalize the last column.\n",
    "            means.append(thismean)\n",
    "            stdevs.append(thisstdev)\n",
    "            featurearray.iloc[ : , featureidx] = \\\n",
    "                (thiscolumn - thismean) / thisstdev\n",
    "        else:\n",
    "            print('FLAG')\n",
    "            means.append(thismean)\n",
    "            thisstdev = 0.1\n",
    "            stdevs.append(thisstdev)\n",
    "            featurearray.iloc[ : , featureidx] = \\\n",
    "                (thiscolumn - thismean) / thisstdev\n",
    "            # We set a small stdev for date.\n",
    "\n",
    "    return featurearray, means, stdevs\n",
    "\n",
    "def model_one_volume(data5tuple):\n",
    "    data, classvector, listtoexclude, i, usedate, regularization = \\\n",
    "        data5tuple\n",
    "    trainingset, yvals, testset = sliceframe(data, \n",
    "                                             classvector, \n",
    "                                             listtoexclude, \n",
    "                                             i)\n",
    "    newmodel = LogisticRegression(C = regularization)\n",
    "    trainingset, means, stdevs = normalizearray(trainingset, usedate)\n",
    "    newmodel.fit(trainingset, yvals)\n",
    "\n",
    "    testset = (testset - means) / stdevs\n",
    "    prediction = newmodel.predict_proba(testset.reshape(1, -1))[0][1]\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    # print(str(i) + \"  -  \" + str(len(listtoexclude)))\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is happening here:\n",
    "\n",
    "- iterates over every volume\n",
    "- removes that volume and any other volumes by the same author from the training set\n",
    "- normalizes the training set by computing the z-score for each feature/feature set\n",
    "- fits the model on the z-scores\n",
    "- normalizes the test data by computing the z-score\n",
    "- using the fitted model, predicts the probability of the test data that it is either reviewed or random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### sliceframe()\n",
    "\n",
    "This function prepares the data for training a model for a specific volume. Given all of the data, all of the classifications, a list of volumes to exclude, and the index of the specific volume to model, this function removes the specific volume and the volumes by the same authors (indicated by `excluderows`) from the training data set (because we are holding out one volume to be classified by the logistic regression). This function then returns a training set, a list of classifications, and the held-out volume to-be-classified once the model has been trained. \n",
    "\n",
    "\n",
    "#### normalizearray()\n",
    "\n",
    "This function computes the z-score for each value in the training set. That is, it loops over each each column in the data structure, subtracts the column mean from each value, and then divides that by the standard deviation. \n",
    "\n",
    "\n",
    "Question:\n",
    "- Why is he normalizing the data by computing z-scores?\n",
    "\n",
    "> In training the model we “normalize” word frequencies by the standard deviation for each word (across the whole dataset). So when we use the model to illuminate specific passages, we also divide coefficients by the standard deviation. This tells us, roughly, how much a single occurrence of a given word would affect the model’s prediction, which is what we’re trying to dramatize when we quote a passage. (page 35)\n",
    "\n",
    "\n",
    "The answer appears to have something to do with using the model's coefficients in the interpretation of the effect of individual words.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "Our investigation into the mechanisms of logistic regression were driven by the question \"what is the regularization value?\"\n",
    "\n",
    "This lead us spend some time watching [Andrew Ng explain classification using Logistic Regression](https://class.coursera.org/ml-005/lecture) on his Coursera course.\n",
    "\n",
    "At a very high level, logistic regression is a machine learning algorithm for performing classification. Logistic regression works by estimating the parameters of a function, the *hypothesis representation*, that divides a multidimensional space into two parts (note, in this case we are talking about binomial or binary logistic regression, which classifies things into one of two bins). The hypothesis representation describes a line that winds its way through the space creating what is called the *decision boundary.* Every data point that lands on one side the boundary gets one label and every data point on the other side of the boundary gets the other label. Similar to linear regression, the goal is to find the best hypothesis representation, that is, the function that best draws a line that divides the space given your already classified data. Once you have a good hypothesis representation, and appropriately *fit* model, you can begin to classify *new* data.\n",
    "\n",
    "The key to logistic regression is estimating the parameters of the hypothesis representation. We can derive the parameters by using the *features* of existing data combined with their already known labels; this is called *training data*. The modeling process, the function call to `newmodel.fit(trainingset, yvals)` in Ted's code above, uses training data–the matrix of poem features in the `data` variable and known labels ('reviewed' or 'random') in the `classvector` variable–to \"learn\" the parameters through a process called *gradient descent* (note: scikit-learn uses a different process called [*coordinate descent*](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) which is exceptionally complex). How gradient descent or the more advanced optimization functions like coordinate descent work are well beyond the scope of the discussion (and our explanatory power) so we will just nod and gesture towards the mathematical magic performed by the `newmodel.fit(trainingset, yvals)` function call.\n",
    "\n",
    "##### Overfitting\n",
    "\n",
    "One of the problems when fitting a logistic regression model is a tendency towards *overfitting*. Crudely this means the model, the function and set of parameters, you estimated have tailored themselves so that they are overly optimized to the data you have. As such, the model becomes less useful for *prediction* or classifying any new data you might encounter. In Ted's case, he is fitting a model based upon all of the poems and their classifications *except one (or a few by the same author)* which he then uses to predict if the *held out* poem was 'reviewed' or 'random.' If he *overfits* the model, it will to a terrible job guessing the status of the held out poem. \n",
    "\n",
    "Regularization is a technique for logistic regression (and other machine learning algorithms) which helps smooth out the tendency toward overfitting with some more mathematical gymnastics that we don't quite have the power to explain with word, but we can explain visually. The diagram below shows how regularization can help with the fitness of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Regularization](notebook_resources/regression_figures.png)\n",
    "\n",
    "*On the left side is a linear regression which doesn't quite fit the data. In the middle is an overfit logistic regression. On right side is a regularized logistic regression.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the diagrams show, the regularized logistic expression (the right side) does have a bit of error, there are pink and blue dots on the wrong sides of the decision boundary, but as more data get added it will generally be more right than the overfitted model as represented by the middle diagram (the squiggly decision boundary). \n",
    "\n",
    "The LinearRegression function of the scikit-learn library allows users to specify a regularization parameter when instantiating a model (`newmodel = LogisticRegression(C = regularization)` in Underwood and Seller's code). They have set the `regularization` parameter to 0.00007. Our question is *why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Regression\n",
    "\n",
    "The code cell below is the scaffolding code that runs the modeling function. This code cell takes a long time to execute, it is training a new model for each book. It uses Python's built in parallel processing modules (`Pool(processes = 4)`) to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning multiprocessing.\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "450\n",
      "500\n",
      "400\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "Multiprocessing concluded.\n"
     ]
    }
   ],
   "source": [
    "# Now do leave-one-out predictions.\n",
    "print('Beginning multiprocessing.')\n",
    "\n",
    "pool = Pool(processes = 4)\n",
    "res = pool.map_async(model_one_volume, sextuplets)\n",
    "\n",
    "# After all files are processed, write metadata, errorlog, and counts of phrases.\n",
    "res.wait()\n",
    "resultlist = res.get()\n",
    "\n",
    "assert len(resultlist) == len(orderedIDs)\n",
    "\n",
    "logisticpredictions = dict()\n",
    "for i, volid in enumerate(orderedIDs):\n",
    "    logisticpredictions[volid] = resultlist[i]\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "print('Multiprocessing concluded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: some commentary here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truepositives = 0\n",
    "truenegatives = 0\n",
    "falsepositives = 0\n",
    "falsenegatives = 0\n",
    "allvolumes = list()\n",
    "\n",
    "with open(outputpath, mode = 'w', encoding = 'utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    header = ['volid', \n",
    "              'reviewed', \n",
    "              'obscure', \n",
    "              'pubdate', \n",
    "              'birthdate', \n",
    "              'gender', \n",
    "              'nation', \n",
    "              'allwords', \n",
    "              'logistic', \n",
    "              'author', \n",
    "              'title', \n",
    "              'pubname', \n",
    "              'actually', \n",
    "              'realclass']\n",
    "    writer.writerow(header)\n",
    "    for volid in IDsToUse:\n",
    "        metadata = metadict[volid]\n",
    "        reviewed = metadata['reviewed']\n",
    "        obscure = metadata['obscure']\n",
    "        pubdate = infer_date(metadata, datetype)\n",
    "        birthdate = metadata['birthdate']\n",
    "        gender = metadata['gender']\n",
    "        nation = metadata['nation']\n",
    "        author = metadata['author']\n",
    "        title = metadata['title']\n",
    "        canonicity = metadata['canonicity']\n",
    "        pubname = metadata['pubname']\n",
    "        allwords = volsizes[volid]\n",
    "        logistic = logisticpredictions[volid]\n",
    "        realclass = classdictionary[volid]\n",
    "        outrow = [volid, \n",
    "                  reviewed, \n",
    "                  obscure, \n",
    "                  pubdate,\n",
    "                  birthdate, \n",
    "                  gender, \n",
    "                  nation, \n",
    "                  allwords, \n",
    "                  logistic, \n",
    "                  author, \n",
    "                  title, \n",
    "                  pubname, \n",
    "                  canonicity, \n",
    "                  realclass]\n",
    "        writer.writerow(outrow)\n",
    "        allvolumes.append(outrow)\n",
    "\n",
    "        if logistic > 0.5 and classdictionary[volid] > 0.5:\n",
    "            truepositives += 1\n",
    "        elif logistic <= 0.5 and classdictionary[volid] < 0.5:\n",
    "            truenegatives += 1\n",
    "        elif logistic <= 0.5 and classdictionary[volid] > 0.5:\n",
    "            falsenegatives += 1\n",
    "        elif logistic > 0.5 and classdictionary[volid] < 0.5:\n",
    "            falsepositives += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Coefficients\n",
    "\n",
    "\n",
    "The code below represents a shift in the focal object of the analysis. In the previous section 720 distinct logistic regressions were trained in order to predict the classification of a single, held-out poem. This is the data that was used to produce the main figure, *Figure 1. Predicted probabilities that volumes come from the reviewed set.* \n",
    "\n",
    "The code below generates a single logistic regression model, trained n *all of the data* with nothing held-out (at least when using the 'full' execution path). The reason no data are held out is because this model is not being used for prediction purposes. Instead, the properties of this model are interrogated directly to better understand how individual features, words, had an effect upon the prediction. This is the analysis that allowed them to label individuals worlds as either red or blue based upon their effect when quoting individual passages.\n",
    "\n",
    "\n",
    "This isn't using computational modeling to *predict* a phenomena, it is using the model to *explore* and *explain* patterns and features of the phenomena. This code describes a process where by the model is being deployed for *exploratory data analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "donttrainon.sort(reverse = True)\n",
    "trainingset, yvals, testset = sliceframe(data, \n",
    "                                         classvector, \n",
    "                                         donttrainon, \n",
    "                                         0)\n",
    "newmodel = LogisticRegression(C = regularization)\n",
    "trainingset, means, stdevs = normalizearray(trainingset, usedate)\n",
    "newmodel.fit(trainingset, yvals)\n",
    "\n",
    "coefficients = newmodel.coef_[0] * 100\n",
    "\n",
    "coefficientuples = list(zip(coefficients, \n",
    "                            (coefficients / np.array(stdevs)), \n",
    "                            vocablist + ['pub.date']))\n",
    "coefficientuples.sort()\n",
    "if verbose:\n",
    "    for coefficient, normalizedcoef, word in coefficientuples:\n",
    "        print(word + \" :  \" + str(coefficient))\n",
    "\n",
    "print()\n",
    "accuracy = (truepositives + truenegatives) / len(IDsToUse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, we don't quite understand is why Ted is normalizing the coefficients. What we don't know is what set of values, the coefficients or the normalized coefficients he is using when he highlights words as either red or blue in the narrative.\n",
    "\n",
    "> In training the model we “normalize” word frequencies by the standard deviation for each word (across the whole dataset). So when we use the model to illuminate specific passages, we also divide coefficients by the standard deviation. This tells us, roughly, how much a single occurrence of a given word would affect the model’s prediction, which is what we’re trying to dramatize when we quote a passage. (page 35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DEFACTORING INSPECTION\n",
    "### how many coeficients are there?\n",
    "len(newmodel.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Output\n",
    "\n",
    "the code below generates the `mainmodelcoefficients.csv` which contains the word, its coefficient and its normalized coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficientpath = outputpath.replace('.csv', '.coefs.csv')\n",
    "with open(coefficientpath, mode = 'w', encoding = 'utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for triple in coefficientuples:\n",
    "        coef, normalizedcoef, word = triple\n",
    "        writer.writerow([word, coef, normalizedcoef])\n",
    "\n",
    "### DEFACTORING FUNCTION RETURN\n",
    "### return accuracy, allvolumes, coefficientuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DEFACTORING NAMESPACE\n",
    "rawaccuracy = accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results\n",
    "\n",
    "The final function of the analysis is to test the accuracy of the model(s). The code below generates a best fit line, using [numpy.polyfit](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html), for all of the results. He then calculates which are predicted-as-reviewed, which is those that fall above this dividing line\n",
    "\n",
    "The accuracy of the dividing line is computed by the total number of predicted-as-reviewed that were actually reviewed divided by the total.\n",
    "\n",
    "Note, this is the accuracy of the dividing line, not the accuracy of the model(s) to predict the reviewed stats of the poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPrTcOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec38ba5630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### DEFACTORING FUNCTION\n",
    "### def diachronic_tilt(allvolumes, modeltype, datelimits):\n",
    "\n",
    "### DEFACTORING FUNCTION PARAMETERS\n",
    "modeltype = 'linear'\n",
    "datelimits = []\n",
    "''' Takes a set of predictions produced by a model that knows nothing about date,\n",
    "and divides it along a line with a diachronic tilt. We need to do this in a way\n",
    "that doesn't violate crossvalidation. I.e., we shouldn't \"know\" anything\n",
    "that the model didn't know. We tried a couple of different ways to do this, but\n",
    "the simplest and actually most reliable is to divide the whole dataset along a\n",
    "linear central trend line for the data!\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "listofrows = list()\n",
    "classvector = list()\n",
    "\n",
    "# DEPRECATED\n",
    "# if modeltype == 'logistic' and len(datelimits) == 2:\n",
    "#     # In this case we construct a subset of data to model on.\n",
    "#     tomodeldata = list()\n",
    "#     tomodelclasses = list()\n",
    "#     pastthreshold, futurethreshold = datelimits\n",
    "\n",
    "for volume in allvolumes:\n",
    "    date = volume[3]\n",
    "    logistic = volume[8]\n",
    "    realclass = volume[13]\n",
    "    listofrows.append([logistic, date])\n",
    "    classvector.append(realclass)\n",
    "\n",
    "    # DEPRECATED\n",
    "    # if modeltype == 'logistic' and len(datelimits) == 2:\n",
    "    #     if date >= pastthreshold and date <= futurethreshold:\n",
    "    #         tomodeldata.append([logistic, date])\n",
    "    #         tomodelclasses.append(realclass)\n",
    "\n",
    "y, x = [a for a in zip(*listofrows)]\n",
    "plt.axis([min(x) - 2, max(x) + 2, min(y) - 0.02, max(y) + 0.02])\n",
    "reviewedx = list()\n",
    "reviewedy = list()\n",
    "randomx = list()\n",
    "randomy = list()\n",
    "\n",
    "for idx, reviewcode in enumerate(classvector):\n",
    "    if reviewcode == 1:\n",
    "        reviewedx.append(x[idx])\n",
    "        reviewedy.append(y[idx])\n",
    "    else:\n",
    "        randomx.append(x[idx])\n",
    "        randomy.append(y[idx])\n",
    "\n",
    "plt.plot(reviewedx, reviewedy, 'ro')\n",
    "plt.plot(randomx, randomy, 'k+')\n",
    "\n",
    "if modeltype == 'logistic':\n",
    "    # all this is DEPRECATED\n",
    "    print(\"Hey, you're attempting to use the logistic-tilt option\")\n",
    "    print(\"that we deactivated. Go in and uncomment the code.\")\n",
    "\n",
    "    # if len(datelimits) == 2:\n",
    "    #     data = pd.DataFrame(tomodeldata)\n",
    "    #     responsevariable = tomodelclasses\n",
    "    # else:\n",
    "    #     data = pd.DataFrame(listofrows)\n",
    "    #     responsevariable = classvector\n",
    "\n",
    "    # newmodel = LogisticRegression(C = 100000)\n",
    "    # newmodel.fit(data, responsevariable)\n",
    "    # coefficients = newmodel.coef_[0]\n",
    "\n",
    "    # intercept = newmodel.intercept_[0] / (-coefficients[0])\n",
    "    # slope = coefficients[1] / (-coefficients[0])\n",
    "\n",
    "    # p = np.poly1d([slope, intercept])\n",
    "\n",
    "elif modeltype == 'linear':\n",
    "    # what we actually do\n",
    "\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    slope = z[0]\n",
    "    intercept = z[1]\n",
    "\n",
    "plt.plot(x,p(x),\"b-\")\n",
    "plt.show(block = False)\n",
    "\n",
    "x = np.array(x, dtype='float64')\n",
    "y = np.array(y, dtype='float64')\n",
    "classvector = np.array(classvector)\n",
    "dividingline = intercept + (x * slope)\n",
    "predicted_as_reviewed = (y > dividingline)\n",
    "really_reviewed = (classvector == 1)\n",
    "\n",
    "accuracy = sum(predicted_as_reviewed == really_reviewed) / len(classvector)\n",
    "\n",
    "### DEFACTORING FUNCTION RETURN\n",
    "### return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DEFACTORING NAMESPACE\n",
    "tiltaccuracy = accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we divide the dataset with a horizontal line at 0.5, accuracy is:  0.775\n",
      "Divided with a line fit to the data trend, it's  0.791666666667\n"
     ]
    }
   ],
   "source": [
    "### DEFACTORING FUNCTION CALL\n",
    "### tiltaccuracy = diachronic_tilt(allvolumes, 'linear', []) \n",
    "\n",
    "print('If we divide the dataset with a horizontal line at 0.5, accuracy is: ', \n",
    "      str(rawaccuracy))\n",
    "\n",
    "print(\"Divided with a line fit to the data trend, it's \", \n",
    "      str(tiltaccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook contains all of the code necessary to run through a full execution of the computational analysis.\n",
    "\n",
    "\n",
    "Open questions for Underwood & Sellers:\n",
    "- why does he normalize the word frequences (using `normalizearray()`) before modeling?\n",
    "- Why does he normalize the coefficients ( divided by standard deviation)?\n",
    "\n",
    "Basically, we don't have a firm understanding of why he is normalizing, mainly because we don't understand the meaning or significance of these steps on the interpretibility of the data. These are probably quite normal practices when performing logistic regression with these kinds of data, but there is a taken for granted quality to these actions that we'd like to see described as part of the methodology (or at least citations to a best practice).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Full concluding remarks are in-progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography ##\n",
    "\n",
    "Frabetti, F., 2012. Have the Humanities Always Been Digital? In *Understanding Digital Humanities.* London; New York: Palgrave Macmillan, pp. 161–171.\n",
    "\n",
    "Anderson, S., McPherson, T., 2011. Engaging Digital Scholarship: Thoughts on Evaluating Multimedia Scholarship. Profession 136–151.\n",
    "\n",
    "Antonijevic, S., 2015. Amongst Digital Humanists: An ethnographic study of digital knowledge production, Palgrave Macmillan.\n",
    "\n",
    "Baldridge, J., 2015. It’s okay for academic software to suck. Java Code Geeks. Available at: https://www.javacodegeeks.com/2015/05/its-okay-for-academic-software-to-suck.html [Accessed April 25, 2016].\n",
    "\n",
    "Braithwaite, R., 2013. Defactoring. Reginald Braithwaite: via raganwald.com. Available at: http://raganwald.com/2013/10/08/defactoring.html [Accessed March 15, 2016].\n",
    "\n",
    "Burgess, H.J. & Hamming, J., 2011. New Media in Academy: Labor and the Production of Knowledge in Scholarly Multimedia. DHQ: Digital Humanities Quarterly, 5(3). Available at: http://digitalhumanities.org/dhq/vol/5/3/000102/000102.html [Accessed September 2, 2016].\n",
    "\n",
    "Clement, T.E., 2016. Where Is Methodology in Digital Humanities? In Debates in the Digital Humanities 2016. University of Minnesota Press, pp. 153–175. Available at: http://dhdebates.gc.cuny.edu/debates/text/65.\n",
    "\n",
    "Enderle, J.S., 2016. A Plot of Brownian Noise. Jonathan Scott Enderle. Available at: https://github.com/senderle/svd-noise/blob/master/Noise.ipynb [Accessed September 24, 2016].\n",
    "\n",
    "Ford, P., 2015. What is Code? Businessweek. Available at: http://www.bloomberg.com/graphics/2015-paul-ford-what-is-code/.\n",
    "\n",
    "Grusin, R., 1994. What is an Electronic Author? Theory and the Technological Fallacy. Configurations, 2(3), pp.469–483.\n",
    "\n",
    "Hiller, M., 2015. Signs o’ the Times: The Software of Philology and a Philology of Software. Digital Culture and Society, 1(1), pp.152–163.\n",
    "\n",
    "Jockers, M.L., 2013. Macroanalysis: Digital Methods and Literary History, Urabana, Chicago, Springfield: UI Press.\n",
    "\n",
    "Kittler, F., 1993. Es gibt keine Software. In Draculas Vermächtmis. Leipzig: Reclam Verlag, pp. 225–242.\n",
    "\n",
    "Knuth, D.E., 1984. Literate Programming. The Computer Journal, 27(1), pp.97–111.\n",
    "\n",
    "Latour, B., 1993. We Have Never Been Modern, Cambridge, Massachusetts: Harvard University Press.\n",
    "\n",
    "Marino, M.C., 2006. Critical Code Studies. Electronic Book Review. Available at: http://www.electronicbookreview.com/thread/electropoetics/codology [Accessed January 16, 2015].\n",
    "\n",
    "Nowviskie, B., 2011. Where Credit Is Due: Preconditions for the Evaluation of Collaborative Digital Scholarship. Profession, pp.169–181.\n",
    "\n",
    "Piper, A., 2015. Novel Devotions: Conversional Reading, Computational Modeling, and the Modern Novel. New Literary History, 46(1), pp.63–98.\n",
    "\n",
    "Presner, T., 2012. How to Evaluate Digital Scholarship. Journal of Digital Humanities, 1(4). Available at: http://journalofdigitalhumanities.org/1-4/how-to-evaluate-digital-scholarship-by-todd-presner/.\n",
    "\n",
    "Purdy, J.P. & Walker, J.R., 2010. Valuing Digital Scholarship: Exploring the Changing Realities of Intellectual Work. Profession, pp.177–195.\n",
    "\n",
    "Rockwell, G., 2011. On the Evaluation of Digital Media as Scholarship. Profession, pp.152–168.\n",
    "\n",
    "Rybicki, J., Hoover, D. & Kestemont, M., 2014. Collaborative authorship: Conrad, Ford and Rolling Delta. Literary and Linguistic Computing, 29(3), pp.422–431.\n",
    "\n",
    "Sahle, P. & Vogeler, G., 2014. Criteria for Reviewing Scholarly Digital Editions (version 1.1). Institut für Dokumentologie und Editorik. Available at: http://www.i-d-e.de/publikationen/weitereschriften/criteria-version-1-1/ [Accessed October 13, 2016].\n",
    "\n",
    "Smithies, J., 2012. Evaluating Scholarly Digital Outputs: The Six Layers Approach. Journal of Digital Humanities, 1(4). Available at: http://journalofdigitalhumanities.org/1-4/evaluating-scholarly-digital-outputs-by-james-smithies/ [Accessed September 2, 2016].\n",
    "\n",
    "Underwood, T., 2014. Understanding Genre in a Collection of a Million Volumes, Interim Report. Figshare. Available at: https://figshare.com/articles/Understanding_Genre_in_a_Collection_of_a_Million_Volumes_Interim_Report/1281251 [Accessed March 15, 2016].\n",
    "\n",
    "Underwood, T. & Sellers, J., 2016. The Longue Durée of Literary Prestige. Modern Language Quarterly, 77(3), pp.321–344.\n",
    "\n",
    "Vee, A., 2013. Understanding Computer Programming as a Literacy. LiCS, 1(2), pp.42–64.\n",
    "\n",
    "Zundert, J.J. van, 2016. Author, Editor, Engineer — Code & the Rewriting of Authorship in Scholarly Editing. Interdisciplinary Science Reviews, 40(4), pp.349–375."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
